{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.rectangles import RectanglesDataLoader\n",
    "from model import feature_extractor\n",
    "from model import descriptor\n",
    "from model import decoder\n",
    "from torch.optim import Adam\n",
    "from model import vasf\n",
    "import torch\n",
    "from trainer import trainer\n",
    "\n",
    "dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = RectanglesDataLoader((16,16),(0,3),(0,3), 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = feature_extractor.CNNFeatureExtractor(128)\n",
    "m2 = descriptor.AutoregressiveMaskedDescriptor(128, 128, 128)\n",
    "m3 = decoder.ImageGenerator(128, 128)\n",
    "vasf_model = vasf.Vasf(m1, m2, m3).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(vasf_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trainer = trainer.SimpleTrainer(train_dl, train_dl, vasf_model, optim, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88849fa5d722466c9868789afc8f6920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mmsamiei/vasf/draft.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.198.96/home/mmsamiei/vasf/draft.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m my_trainer\u001b[39m.\u001b[39;49mtrain(\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/vasf/trainer/trainer.py:24\u001b[0m, in \u001b[0;36mSimpleTrainer.train\u001b[0;34m(self, num_iter, log_every_step)\u001b[0m\n\u001b[1;32m     22\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(reconstructed, images) \u001b[39m+\u001b[39m commit_loss\n\u001b[1;32m     23\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 24\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m \u001b[39m%\u001b[39m log_every_step \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/optim/adam.py:133\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 133\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[1;32m    134\u001b[0m            grads,\n\u001b[1;32m    135\u001b[0m            exp_avgs,\n\u001b[1;32m    136\u001b[0m            exp_avg_sqs,\n\u001b[1;32m    137\u001b[0m            max_exp_avg_sqs,\n\u001b[1;32m    138\u001b[0m            state_steps,\n\u001b[1;32m    139\u001b[0m            amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    140\u001b[0m            beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    141\u001b[0m            beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    142\u001b[0m            lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    143\u001b[0m            weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    144\u001b[0m            eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/optim/_functional.py:87\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m     86\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m---> 87\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad\u001b[39m.\u001b[39;49mconj(), value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m amsgrad:\n\u001b[1;32m     89\u001b[0m     \u001b[39m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     torch\u001b[39m.\u001b[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001b[39m=\u001b[39mmax_exp_avg_sqs[i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_trainer.train(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22bd7f4c9c59134fee0b8796bda808c99b2b059b223a50ebf01f5bf1ee364b85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
